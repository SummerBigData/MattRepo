# Import the necessary pachages
import scipy.ndimage
import struct as st
import gzip
import scipy.io
import scipy.optimize
import numpy as np
import matplotlib.pyplot as plt

# Reading in MNIST data files
def read_idx(filename, n=None):
	with gzip.open(filename) as f:
		zero, dtype, dims = st.unpack('>HBB', f.read(4))
		shape = tuple(st.unpack('>I', f.read(4))[0] for d in range(dims))
		arr = np.fromstring(f.read(), dtype=np.uint8).reshape(shape)
		if not n is None:
			arr = arr[:n]
		return arr

# Sigmoid function
def sigmoid(value):
	return 1.0 / (1.0 + np.exp(-value))

# Feedforward
def feedforward(theta1, theta2, arr_x):

	# We will be running our sigmoid function twice
	a2 = sigmoid(np.dot(arr_x, theta1.T))	

	# Add a column of ones to our array of a2
	arr_ones = np.ones((m, 1))
	a2 = np.hstack((arr_ones, a2))        # (5000, 26) matrix

	# Second run
	a3 = sigmoid(np.dot(a2, theta2.T))    # (5000, 10) matrix

	return a3

# Set up how large we want our data set (max of 10,000)
size = 10000

# Extract the MNIST test data sets
x_vals = read_idx('data/t10k-images-idx3-ubyte.gz', size)
x_vals = x_vals / 255.0
x_vals = np.reshape(x_vals, (x_vals.shape[0], (x_vals.shape[1] * x_vals.shape[2])))
y_vals = read_idx('data/t10k-labels-idx1-ubyte.gz', size)
y_vals = np.reshape(y_vals, (len(y_vals), 1))


# Rotate the images (not working properly)
for i in range(len(x_vals)):
	temp = np.reshape(x_vals[i], (28, 28))
	temp = scipy.ndimage.rotate(temp, 30, reshape = False)
	temp = np.ravel(temp)
	x_vals[i] = temp

print x_vals[0]
# Add a column of ones to our array of x_vals
m = len(x_vals)                               # Number of training examples (rows)
arr_ones = np.ones((m, 1))
x_vals = np.hstack((arr_ones, x_vals))
n = len(x_vals[0])                            # Number of columns

# Import the theta valus that we found earlier
theta = np.genfromtxt("outputs/finalMNIST60000Hour3.out")
theta_vals1 = np.reshape(theta[0:25 * n], (25, n))
theta_vals2 = np.reshape(theta[25 * n: len(theta)], (10, 26))

# Find the probabilities for each digit
prob_all = feedforward(theta_vals1, theta_vals2, x_vals)

# Find the largest value in each column
best_prob = np.zeros((len(prob_all), 1))
for i in range (len(prob_all)):
	best_prob[i, 0] = np.argmax(prob_all[i, :])
	 
# Find how accurate our program was with identifying the correct number
correct_guess = np.zeros((10, 1))
for i in range(len(best_prob)):
	if (best_prob[i] == int(y_vals[i])):
		correct_guess[int(y_vals[i])] = correct_guess[int(y_vals[i])] + 1

# Find how many of each number of our array y has
y_digits = np.zeros((10, 1))
for i in range(10):
	for j in range(len(y_vals)):
		if (y_vals[j] == i):
			y_digits[i] = y_digits[i] + 1

# Calculate the percentage
for i in range(len(correct_guess)):
	correct_guess[i] = (correct_guess[i] / y_digits[i]) * 100

# Check the results
print correct_guess

# Calculate the average accuracy
avg_acc = 0
for i in range(len(correct_guess)):
	avg_acc = avg_acc + correct_guess[i]

avg_acc = avg_acc / len(correct_guess)
print avg_acc

