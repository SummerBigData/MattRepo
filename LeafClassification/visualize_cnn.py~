# From: https://www.kaggle.com/abhmul/keras-convnet-lb-0-0052-w-visualization/notebook
from math import sqrt

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder   # Preprocessing
from sklearn.preprocessing import StandardScaler # Preprocessing
import matplotlib.image as mpimg           	 # Reading images to numpy arrays   
from keras import backend as K
from keras.models import load_model
from keras.layers import MaxPooling2D
from scipy.misc import imresize
from keras.utils import np_utils

global_num_train = 990
global_num_test = 594
global_total_img = global_num_train + global_num_test
NUM_LEAVES = 3
global_max_dim = 100
model_fn = 'bestWeights.hdf5'

####### Definitions #######
# Set up all of the images in a matrix
def grab_images(tr_ids, te_ids):
	# Full set
	matrix = np.zeros((2, global_total_img))
	images_list = []
	for i in range(global_total_img):
		img = mpimg.imread('data_provided/unzip_images/images/' + str(i + 1) + '.jpg')
		matrix[:,i] = np.shape(img)
		images_list.append(img)

	# We will want to learn features on the images that belong to our training set	
	train_list = []
	for i, img in enumerate(tr_ids):
		train_list.append(images_list[img - 1])
	
	# We might want to look at some test images too	
	test_list = []
	for i, img in enumerate(te_ids):
		test_list.append(images_list[img - 1])

	return images_list, train_list, test_list

def resize_img(img, max_dim):
    	# Get the axis with the larger dimension
    	max_ax = max((0, 1), key=lambda i: img.shape[i])
    	# Scale both axes so the image's largest dimension is max_dim
   	scale = max_dim / float(img.shape[max_ax])
    	return np.resize(img, (int(img.shape[0] * scale), int(img.shape[1] * scale)))

def reshape_img(images, max_dim, center = True):
	
	modified = np.zeros((len(images), max_dim, max_dim, 1))
	for i in range(len(images)):
		temp = resize_img(images[i], max_dim = max_dim)
		x = imresize(images[i], (temp.shape[0], temp.shape[1]), interp = 'nearest').reshape(temp.shape[0], 
			temp.shape[1], 1)

		length = x.shape[0]
		width = x.shape[1]
		if center:
			h1 = int((max_dim - length) / 2)
           	 	h2 = h1 + length
           		w1 = int((max_dim - width) / 2)
          		w2 = w1 + width
       		else:
           		h1, w1 = 0, 0
          		h2, w2 = (length, width)
	
		modified[i, h1:h2, w1:w2, 0:1] = x

	return  np.around(modified / 255.0)

# Function by gcalmettes from http://stackoverflow.com/questions/11159436/multiple-figures-in-a-single-window
def plot_figures(figures, nrows = 1, ncols=1, titles=False):
    """Plot a dictionary of figures.

    Parameters
    ----------
    figures : <title, figure> dictionary
    ncols : number of columns of subplots wanted in the display
    nrows : number of rows of subplots wanted in the figure
    """

    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows)
    for ind,title in enumerate(sorted(figures.keys(), key=lambda s: int(s[3:]))):
        axeslist.ravel()[ind].imshow(figures[title], cmap=plt.gray())
        if titles:
            axeslist.ravel()[ind].set_title(title)

    for ind in range(nrows*ncols):
        axeslist.ravel()[ind].set_axis_off()

    if titles:
        plt.tight_layout()
    plt.show()


def get_dim(num):
    """
    Simple function to get the dimensions of a square-ish shape for plotting
    num images
    """

    s = sqrt(num)
    if round(s) < s:
        return (int(s), int(s)+1)
    else:
        return (int(s)+1, int(s)+1)

def engineered_features(train, test, tr_list, te_list):
	'''
	Create more features that can be obtained from characteristics of the images

	Parameters:
	te_list - list of the training images
	tr_list - list of the testing images
	train - array of pre-extracted features for the training set
	test - array of pre-extracted features for the testing set

	Return:
	test_mod - array of pre-extracted features for the training set with engineered features
	train_mod - array of pre-extracted features for the test set with engineered features
	'''
	# Initialize each array
	tr_width = np.zeros((len(tr_list), 1)) 
	tr_height = np.zeros((len(tr_list), 1))
	tr_asp_ratio = np.zeros((len(tr_list), 1))
	tr_square = np.zeros((len(tr_list), 1))
	te_width = np.zeros((len(te_list), 1))
	te_height = np.zeros((len(te_list), 1))
	te_asp_ratio = np.zeros((len(te_list), 1))
	te_square = np.zeros((len(te_list), 1))

	# Calculate the features of the training images
	for i in range(len(tr_list)):
		tr_width[i] = tr_list[i].shape[1]
		tr_height[i] = tr_list[i].shape[0]
		tr_asp_ratio[i] = tr_list[i].shape[1] / tr_list[i].shape[0]
		tr_square[i] = tr_list[i].shape[1] * tr_list[i].shape[0]

	# Calculate the features of the test images
	for i in range(len(te_list)):
		te_width[i] = te_list[i].shape[1]
		te_height[i] = te_list[i].shape[0]
		te_asp_ratio[i] = te_list[i].shape[1] / te_list[i].shape[0]
		te_square[i] = te_list[i].shape[1] * te_list[i].shape[0]

	# Attach these features to the pre-extracted ones
	train_mod = np.concatenate((train, tr_width, tr_height, tr_asp_ratio, tr_square), axis = 1)
	test_mod = np.concatenate((test, te_width, te_height, te_asp_ratio, te_square), axis = 1)

	return train_mod, test_mod

# Load the best model
model = load_model(model_fn)

# We need to extract the data given
# Set up our training data
train = pd.read_csv('data_provided/train.csv')

# Extract the species of each leaf
y_raw = train.pop('species')

# Label each species from 0 - n-1
le = LabelEncoder()
# fit() calculates the mean and std, transform() centers and scales data
y = le.fit(y_raw).transform(y_raw)
			
# Grab the classes (will be used to set up our submition file)
classes = le.classes_
# Setting up one-hot scheme
y_train = np_utils.to_categorical(y)

# Extract the id of each leaf
train_ids = train.pop('id')

# Set up our testing data
test = pd.read_csv('data_provided/test.csv')

# Extract the id of each leaf
test_ids = test.pop('id')

# Load up all of the images
print 'Loading images...'
img_list, train_list, test_list = grab_images(train_ids, test_ids)
print 'Finished.'
	
# We need to reshape our images so they are all the same dimensions
train_mod_list = reshape_img(train_list, global_max_dim)
test_mod_list = reshape_img(test_list, global_max_dim)

# Grab more features to train on
train, test = engineered_features(train, test, train_list, test_list)

x_train = StandardScaler().fit_transform(train)
x_test = StandardScaler().fit_transform(test)

# Set up our input layer size
global_input_layer = x_train.shape[1]

X_img_val = train_mod_list[global_num_train - 99: global_num_train]
X_num_val = x_train[global_num_train - 99: global_num_train]
y_val = y[global_num_train - 99: global_num_train]

# Get the convolutional layers
conv_layers = [layer for layer in model.layers if isinstance(layer, MaxPooling2D)]

# Pick random images to visualize
imgs_to_visualize = np.random.choice(np.arange(0, len(X_img_val)), NUM_LEAVES)

# Use a keras function to extract the conv layer data
convout_func = K.function([model.layers[0].input, K.learning_phase()], [layer.output for layer in conv_layers])
conv_imgs_filts = convout_func([X_img_val[imgs_to_visualize], 0])
# Also get the prediction so we know what we predicted
predictions = model.predict([X_img_val[imgs_to_visualize], X_num_val[imgs_to_visualize]])

imshow = plt.imshow #alias
# Loop through each image disply relevant info
for img_count, img_to_visualize in enumerate(imgs_to_visualize):

    # Get top 3 predictions
    top3_ind = predictions[img_count].argsort()[-3:]
    top3_species = np.array(classes)[top3_ind]
    top3_preds = predictions[img_count][top3_ind]

    # Get the actual leaf species
    actual = classes[y_val[img_to_visualize]]

    # Display the top 3 predictions and the actual species
    print("Top 3 Predicitons:")
    for i in range(2, -1, -1):
        print("\t%s: %s" % (top3_species[i], top3_preds[i]))
    print("\nActual: %s" % actual)

    # Show the original image
    plt.title("Image used: #%d (digit=%d)" % (img_to_visualize, y_val[img_to_visualize]))
    imshow(X_img_val[img_to_visualize][:, :, 0], cmap='gray', interpolation = 'none')
    plt.tight_layout()
    plt.show()

    # Plot the filter images
    for i, conv_imgs_filt in enumerate(conv_imgs_filts):
        conv_img_filt = conv_imgs_filt[img_count]
        print("Visualizing Convolutions Layer %d" % i)
        # Get it ready for the plot_figures function
        fig_dict = {'flt{0}'.format(i): conv_img_filt[:, :, i] for i in range(conv_img_filt.shape[-1])}
        plot_figures(fig_dict, *get_dim(len(fig_dict)))
