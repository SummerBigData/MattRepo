Using TensorFlow backend.
Loading images...
Finished.
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
input_1 (InputLayer)             (None, 100, 100, 1)   0                                            
____________________________________________________________________________________________________
conv2d_1 (Conv2D)                (None, 100, 100, 32)  832         input_1[0][0]                    
____________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)   (None, 10, 10, 32)    0           conv2d_1[0][0]                   
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 10, 10, 32)    0           max_pooling2d_1[0][0]            
____________________________________________________________________________________________________
conv2d_2 (Conv2D)                (None, 10, 10, 8)     6408        dropout_1[0][0]                  
____________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)   (None, 2, 2, 8)       0           conv2d_2[0][0]                   
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 2, 2, 8)       0           max_pooling2d_2[0][0]            
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 32)            0           dropout_2[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 192)           6336        flatten_1[0][0]                  
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 192)           0           dense_1[0][0]                    
____________________________________________________________________________________________________
input_2 (InputLayer)             (None, 192)           0                                            
____________________________________________________________________________________________________
concatenate_1 (Concatenate)      (None, 384)           0           dropout_3[0][0]                  
                                                                   input_2[0][0]                    
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 400)           154000      concatenate_1[0][0]              
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 400)           0           dense_2[0][0]                    
____________________________________________________________________________________________________
dense_3 (Dense)                  (None, 280)           112280      dropout_4[0][0]                  
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 280)           0           dense_3[0][0]                    
____________________________________________________________________________________________________
dense_4 (Dense)                  (None, 140)           39340       dropout_5[0][0]                  
____________________________________________________________________________________________________
dropout_6 (Dropout)              (None, 140)           0           dense_4[0][0]                    
____________________________________________________________________________________________________
dense_5 (Dense)                  (None, 99)            13959       dropout_6[0][0]                  
====================================================================================================
Total params: 333,155
Trainable params: 333,155
Non-trainable params: 0
____________________________________________________________________________________________________
None
2018-07-19 15:30:33.291670: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-19 15:30:33.291709: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
Epoch 00000: val_loss improved from inf to 4.08785, saving model to bestWeights2.hdf5
Epoch 00001: val_loss improved from 4.08785 to 2.95077, saving model to bestWeights2.hdf5
Epoch 00002: val_loss improved from 2.95077 to 1.53981, saving model to bestWeights2.hdf5
Epoch 00003: val_loss improved from 1.53981 to 0.80755, saving model to bestWeights2.hdf5
Epoch 00004: val_loss improved from 0.80755 to 0.43326, saving model to bestWeights2.hdf5
Epoch 00005: val_loss improved from 0.43326 to 0.30497, saving model to bestWeights2.hdf5
Epoch 00006: val_loss improved from 0.30497 to 0.23952, saving model to bestWeights2.hdf5
Epoch 00007: val_loss improved from 0.23952 to 0.22402, saving model to bestWeights2.hdf5
Epoch 00008: val_loss improved from 0.22402 to 0.10088, saving model to bestWeights2.hdf5
Epoch 00009: val_loss did not improve
Epoch 00010: val_loss improved from 0.10088 to 0.09876, saving model to bestWeights2.hdf5
Epoch 00011: val_loss did not improve
Epoch 00012: val_loss improved from 0.09876 to 0.09293, saving model to bestWeights2.hdf5
Epoch 00013: val_loss improved from 0.09293 to 0.06628, saving model to bestWeights2.hdf5
Epoch 00014: val_loss did not improve
Epoch 00015: val_loss improved from 0.06628 to 0.03928, saving model to bestWeights2.hdf5
Epoch 00016: val_loss improved from 0.03928 to 0.03616, saving model to bestWeights2.hdf5
Epoch 00017: val_loss did not improve
Epoch 00018: val_loss did not improve
Epoch 00019: val_loss did not improve
Epoch 00020: val_loss did not improve
Epoch 00021: val_loss did not improve
Epoch 00022: val_loss did not improve
Epoch 00023: val_loss did not improve
Epoch 00024: val_loss improved from 0.03616 to 0.02331, saving model to bestWeights2.hdf5
Epoch 00025: val_loss did not improve
Epoch 00026: val_loss did not improve
Epoch 00027: val_loss improved from 0.02331 to 0.02309, saving model to bestWeights2.hdf5
Epoch 00028: val_loss did not improve
Epoch 00029: val_loss did not improve
Epoch 00030: val_loss did not improve
Epoch 00031: val_loss improved from 0.02309 to 0.02291, saving model to bestWeights2.hdf5
Epoch 00032: val_loss did not improve
Epoch 00033: val_loss did not improve
Epoch 00034: val_loss did not improve
Epoch 00035: val_loss improved from 0.02291 to 0.01727, saving model to bestWeights2.hdf5
Epoch 00036: val_loss did not improve
Epoch 00037: val_loss did not improve
Epoch 00038: val_loss did not improve
Epoch 00039: val_loss did not improve
Epoch 00040: val_loss did not improve
Epoch 00041: val_loss did not improve
Epoch 00042: val_loss did not improve
Epoch 00043: val_loss did not improve
Epoch 00044: val_loss did not improve
Epoch 00045: val_loss did not improve
Epoch 00046: val_loss did not improve
Epoch 00047: val_loss did not improve
Epoch 00048: val_loss did not improve
Epoch 00049: val_loss did not improve
Epoch 00050: val_loss did not improve
Epoch 00051: val_loss did not improve
Epoch 00052: val_loss did not improve
Epoch 00053: val_loss did not improve
Epoch 00054: val_loss did not improve
Epoch 00055: val_loss improved from 0.01727 to 0.01625, saving model to bestWeights2.hdf5
Epoch 00056: val_loss did not improve
Epoch 00057: val_loss did not improve
Epoch 00058: val_loss did not improve
Epoch 00059: val_loss did not improve
Epoch 00060: val_loss did not improve
Epoch 00061: val_loss improved from 0.01625 to 0.01543, saving model to bestWeights2.hdf5
Epoch 00062: val_loss did not improve
Epoch 00063: val_loss did not improve
Epoch 00064: val_loss did not improve
Epoch 00065: val_loss did not improve
Epoch 00066: val_loss did not improve
Epoch 00067: val_loss improved from 0.01543 to 0.01517, saving model to bestWeights2.hdf5
Epoch 00068: val_loss improved from 0.01517 to 0.01236, saving model to bestWeights2.hdf5
Epoch 00069: val_loss improved from 0.01236 to 0.01112, saving model to bestWeights2.hdf5
Epoch 00070: val_loss did not improve
Epoch 00071: val_loss did not improve
Epoch 00072: val_loss did not improve
Epoch 00073: val_loss did not improve
Epoch 00074: val_loss improved from 0.01112 to 0.00815, saving model to bestWeights2.hdf5
Epoch 00075: val_loss did not improve
Epoch 00076: val_loss did not improve
Epoch 00077: val_loss did not improve
Epoch 00078: val_loss did not improve
Epoch 00079: val_loss did not improve
Epoch 00080: val_loss did not improve
Epoch 00081: val_loss did not improve
Epoch 00082: val_loss did not improve
Epoch 00083: val_loss did not improve
Epoch 00084: val_loss improved from 0.00815 to 0.00703, saving model to bestWeights2.hdf5
Epoch 00085: val_loss did not improve
Epoch 00086: val_loss did not improve
Epoch 00087: val_loss did not improve
Epoch 00088: val_loss did not improve
Epoch 00089: val_loss did not improve
Epoch 00090: val_loss did not improve
Epoch 00091: val_loss did not improve
Epoch 00092: val_loss did not improve
Epoch 00093: val_loss did not improve
Epoch 00094: val_loss did not improve
Epoch 00095: val_loss did not improve
Epoch 00096: val_loss did not improve
Epoch 00097: val_loss did not improve
Epoch 00098: val_loss did not improve
Epoch 00099: val_loss did not improve


Saving to file...
Finished.
